{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f572ea4c",
   "metadata": {},
   "source": [
    "# **2D-CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5e1468",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmne_bids\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mne_bids/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne_bids\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mread\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_head_mri_trans, read_raw_bids\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne_bids\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_anonymization_daysback\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne_bids\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (make_dataset_description, write_anat,\n\u001b[1;32m     13\u001b[0m                             write_raw_bids, mark_channels,\n\u001b[1;32m     14\u001b[0m                             write_meg_calibration, write_meg_crosstalk,\n\u001b[1;32m     15\u001b[0m                             get_anat_landmarks, anonymize_dataset)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne_bids\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msidecar_updates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_sidecar_json, update_anat_landmarks\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne_bids\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspect_dataset\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mne_bids/write.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpkg_resources\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_get_trans, apply_trans, rotation, translation)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1039\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:211\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/linalg/__init__.py:199\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_misc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cythonized_array_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp_lu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/linalg/_basic.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m atleast_1d, atleast_2d\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_flinalg_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_flinalg_funcs\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs, _compute_lwork\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_misc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinAlgError, _datacopied, LinAlgWarning\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/linalg/_flinalg_py.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The following ensures that possibly missing flavor (C or Fortran) is\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# replaced with the available one. If none is available, exception\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# is raised at the first attempt to use the resources.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _flinalg\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     _flinalg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pandas as pd\n",
    "import mne_bids\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import soundfile as sf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.fftpack\n",
    "import librosa\n",
    "from Extra import WaveGlow_functions\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, InputLayer, Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import gc\n",
    "from Extra import MelFilterBank as mel\n",
    "from Extra import reconstructWave as rW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178db228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TensorFlow GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba85a7",
   "metadata": {},
   "source": [
    "### **Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9bd06",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Small helper function to speed up the hilbert transform by extending the length of data to the next power of 2\n",
    "hilbert3 = lambda x: scipy.signal.hilbert(\n",
    "    x, scipy.fftpack.next_fast_len(len(x)), axis=0)[:len(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160075d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extractHG(data,\n",
    "              sr,\n",
    "              windowLength=0.05,\n",
    "              frameshift=0.01,\n",
    "              bandpass_min=70,\n",
    "              bandpass_max=170):\n",
    "    \"\"\"\n",
    "    Window data and extract frequency-band envelope using the hilbert transform\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: array (samples, channels)\n",
    "        EEG time series\n",
    "    sr: int\n",
    "        Sampling rate of the data\n",
    "    windowLength: float\n",
    "        Length of window (in seconds) in which spectrogram will be calculated\n",
    "    frameshift: float\n",
    "        Shift (in seconds) after which next window will be extracted\n",
    "    Returns\n",
    "    ----------\n",
    "    feat: array (windows, channels)\n",
    "        Frequency-band feature matrix\n",
    "    \"\"\"\n",
    "    #Linear detrend\n",
    "    data = scipy.signal.detrend(data, axis=0)\n",
    "    #Number of windows\n",
    "    numWindows = int(\n",
    "        np.floor((data.shape[0] - windowLength * sr) / (frameshift * sr)))\n",
    "    #Filter High-Gamma Band\n",
    "    # sos = scipy.signal.iirfilter(4, [70/(sr/2),170/(sr/2)],btype='bandpass',output='sos')\n",
    "    sos = scipy.signal.iirfilter(\n",
    "        4, [bandpass_min / (sr / 2), bandpass_max / (sr / 2)],\n",
    "        btype='bandpass',\n",
    "        output='sos')\n",
    "    data = scipy.signal.sosfiltfilt(sos, data, axis=0)\n",
    "    #Attenuate first harmonic of line noise\n",
    "    # sos = scipy.signal.iirfilter(4, [98/(sr/2),102/(sr/2)],btype='bandstop',output='sos')\n",
    "    # data = scipy.signal.sosfiltfilt(sos,data,axis=0)\n",
    "    #Attenuate second harmonic of line noise\n",
    "    # sos = scipy.signal.iirfilter(4, [148/(sr/2),152/(sr/2)],btype='bandstop',output='sos')\n",
    "    # data = scipy.signal.sosfiltfilt(sos,data,axis=0)\n",
    "    #Create feature space\n",
    "    data = np.abs(hilbert3(data))\n",
    "    feat = np.zeros((numWindows, data.shape[1]))\n",
    "    for win in range(numWindows):\n",
    "        start = int(np.floor((win * frameshift) * sr))\n",
    "        stop = int(np.floor(start + windowLength * sr))\n",
    "        feat[win, :] = np.mean(data[start:stop, :], axis=0)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740dbe7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def stackFeatures(features, modelOrder=4, stepSize=5):\n",
    "    \"\"\"\n",
    "    Add temporal context to each window by stacking neighboring feature vectors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features: array (windows, channels)\n",
    "        Feature time series\n",
    "    modelOrder: int\n",
    "        Number of temporal context to include prior to and after current window\n",
    "    stepSize: float\n",
    "        Number of temporal context to skip for each next context (to compensate for frameshift)\n",
    "    Returns\n",
    "    ----------\n",
    "    featStacked: array (windows, feat*(2*modelOrder+1))\n",
    "        Stacked feature matrix\n",
    "    \"\"\"\n",
    "    featStacked = np.zeros((features.shape[0] - (2 * modelOrder * stepSize),\n",
    "                            (2 * modelOrder + 1) * features.shape[1]))\n",
    "    for fNum, i in enumerate(\n",
    "            range(modelOrder * stepSize,\n",
    "                  features.shape[0] - modelOrder * stepSize)):\n",
    "        ef = features[i - modelOrder * stepSize:i + modelOrder * stepSize +\n",
    "                      1:stepSize, :]\n",
    "        featStacked[\n",
    "            fNum, :] = ef.flatten()  #Add 'F' if stacked the same as matlab\n",
    "    return featStacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec2377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaveGlow / Tacotron2 / STFT parameters for audio data\n",
    "# samplingFrequency = 16000\n",
    "samplingFrequency = 22050\n",
    "#samplingFrequency_EEG = 512 #sub 07\n",
    "winL_EEG =  ( 0.05)\n",
    "# frameshift_EEG = 0.01 # 10 ms\n",
    "frameshift_EEG = 0.01  # 10 ms\n",
    "frameshift_speech = 220  # 10ms\n",
    "# modelOrder_EEG = 1\n",
    "# modelOrder_EEG = 2\n",
    "modelOrder_EEG = 4\n",
    "# modelOrder_EEG = 10\n",
    "stepSize_EEG = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac943e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = WaveGlow_functions.TacotronSTFT(filter_length=1024,\n",
    "                                       hop_length=frameshift_speech,\n",
    "                                       win_length=1024,\n",
    "                                       n_mel_channels=80,\n",
    "                                       sampling_rate=samplingFrequency,\n",
    "                                       mel_fmin=0,\n",
    "                                       mel_fmax=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef706b",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Load the original audio file\n",
    "y, sr = librosa.load('data/stimuli/6min.wav', sr=None)  # Load with original sampling rate\n",
    "\n",
    "print(\"Sampling rate before:\", sr, \"Hz\")\n",
    "# Resample to 22050 Hz\n",
    "y_22050 = librosa.resample(y, orig_sr=sr, target_sr=22050)\n",
    "\n",
    "# Save the resampled audio to a new file\n",
    "sf.write('resampled_audio_22050Hz.wav', y_22050, 22050)\n",
    "\n",
    "# Use the resampled file in your processing pipeline\n",
    "wavfile = 'resampled_audio_22050Hz.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22831591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the resampled audio file\n",
    "y, sr = librosa.load('resampled_audio_22050Hz.wav', sr=22050)\n",
    "\n",
    "# Shift the audio by 150 ms\n",
    "shift_ms = 150  # milliseconds\n",
    "shift_samples = int(sr * (shift_ms / 1000.0))  # Convert milliseconds to samples\n",
    "shifted_audio = np.pad(y, (shift_samples, 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "# Save the shifted audio to a new file\n",
    "sf.write('shifted_audio_22050Hz.wav', shifted_audio, sr)\n",
    "\n",
    "# Now you can compute the mel-spectrogram of the shifted audio\n",
    "wavfile = 'shifted_audio_22050Hz.wav'\n",
    "mel_data = WaveGlow_functions.get_mel(wavfile, stft)\n",
    "mel_data_nonrot = mel_data\n",
    "mel_data = np.fliplr(np.rot90(mel_data.data.numpy(), axes=(1, 0)))\n",
    "\n",
    "\n",
    "# Print shapes and durations\n",
    "print(\"Original audio duration (seconds):\", len(y) / sr)\n",
    "print(\"Shifted audio duration (seconds):\", len(shifted_audio) / sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Subjects\n",
    "bids_dir = 'data'\n",
    "subjects = mne_bids.get_entity_vals(bids_dir, 'subject')\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose subjects\n",
    "subject = '13'\n",
    "acquisition = 'clinical'\n",
    "task = 'film'\n",
    "datatype = 'ieeg'\n",
    "session = 'iemu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3022aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load subject's channels\n",
    "channels_path = mne_bids.BIDSPath(subject=subject,\n",
    "                                  session=session,\n",
    "                                  suffix='channels',\n",
    "                                  extension='tsv',\n",
    "                                  datatype=datatype,\n",
    "                                  task=task,\n",
    "                                  acquisition=acquisition,\n",
    "                                  root=bids_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = pd.read_csv(str(channels_path.match()[0]),\n",
    "                       sep='\\t',\n",
    "                       header=0,\n",
    "                       index_col=None)\n",
    "#print(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e2b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set channel types\n",
    "data_path = mne_bids.BIDSPath(subject=subject,\n",
    "                              session=session,\n",
    "                              suffix='ieeg',\n",
    "                              extension='vhdr',\n",
    "                              datatype=datatype,\n",
    "                              task=task,\n",
    "                              acquisition=acquisition,\n",
    "                              root=bids_dir)\n",
    "raw = mne.io.read_raw_brainvision(str(data_path.match()[0]),\n",
    "                                  scale=1.0,\n",
    "                                  preload=False,\n",
    "                                  verbose=True)\n",
    "raw.set_channel_types({\n",
    "    ch_name:\n",
    "    str(x).lower() if str(x).lower() in ['ecog', 'seeg', 'eeg'] else 'misc'\n",
    "    for ch_name, x in zip(raw.ch_names, channels['type'].values)\n",
    "})\n",
    "raw.drop_channels([\n",
    "    raw.ch_names[i] for i, j in enumerate(raw.get_channel_types())\n",
    "    if j == 'misc'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501706bb",
   "metadata": {},
   "source": [
    "### Discard Bad Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83882f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad channels\n",
    "bad_channels = channels['name'][(channels['type'].isin(['ECOG', 'SEEG']))\n",
    "                                & (channels['status'] == 'bad')].tolist()\n",
    "raw.info['bads'].extend([ch for ch in bad_channels])\n",
    "raw.drop_channels(raw.info['bads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad223c",
   "metadata": {},
   "source": [
    "### Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae79701",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eeg_channels = int(raw.info['nchan'])  # for subject 01\n",
    "print('n_eeg_channels', n_eeg_channels)\n",
    "# raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e11f21",
   "metadata": {},
   "source": [
    "### Apply notch filter to remove line noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.notch_filter(freqs=np.arange(50, 251, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a92fe",
   "metadata": {},
   "source": [
    "### Apply common average reference to remove common noise and trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be08d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAR\n",
    "raw_car, _ = mne.set_eeg_reference(raw.copy(), 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4bfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = raw_car.copy().filter(60,\n",
    "                              120).apply_hilbert(envelope=True).get_data()  #.T\n",
    "print('raw_car.shape:', raw_car._data.shape, 'gamma shape: ', gamma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad375f65",
   "metadata": {},
   "source": [
    "#Extract signal in gamma range, use Hilbert transform, but can also play around with wavelet decomposition options\n",
    "\n",
    "\n",
    "gamma = raw_car.copy().filter(60, 120).apply_hilbert(envelope=True).get_data().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b220ef9",
   "metadata": {},
   "source": [
    "### Read annotation with event markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0237f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "custom_mapping = {\n",
    "    'Stimulus/music': 2,\n",
    "    'Stimulus/speech': 1,\n",
    "    'Stimulus/end task': 5\n",
    "}  # 'Stimulus/task end' in laan\n",
    "events, event_id = mne.events_from_annotations(raw_car,\n",
    "                                               event_id=custom_mapping,\n",
    "                                               use_rounding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "raw_car.plot(n_channels=30, scalings='auto', duration=3, start=29)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume gamma is a 2D array\n",
    "np.savetxt(\"gamma.tsv\", gamma, delimiter=\"\\t\")\n",
    "\n",
    "n_melspec = 80\n",
    "#get EEG SR\n",
    "samplingFrequency_EEG = raw_car.info['sfreq']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f7173",
   "metadata": {},
   "source": [
    "### Crop to keep only the segments while wathcing the stimuli ( 6.5 min long movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg=raw_car.get_data()\n",
    "\n",
    "\n",
    "#create a copy taht we crop\n",
    "raw_car_cut = raw_car.get_data()\n",
    "print(raw_car_cut.shape)\n",
    "#(n_channels, n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before cut: ', raw_car._data.shape, mel_data.shape)\n",
    "\n",
    "raw_car_cut = np.empty((n_eeg_channels, 0))\n",
    "mel_data_cut = np.empty((0, n_melspec))\n",
    "\n",
    "# for i in range(6):\n",
    "for i in range(6):\n",
    "    start_time = events[2 * i + 1, 0] / raw_car.info['sfreq']\n",
    "    end_time = events[2 * i + 2, 0] / raw_car.info['sfreq']\n",
    "    start_idx, end_idx = raw_car.time_as_index([start_time, end_time])\n",
    "    print(i, 'iEEG index', start_idx, end_idx, end_idx - start_idx)\n",
    "    n_frames_per_sec = int(1 / frameshift_EEG)\n",
    "    print(i, 'melspec index', (2 * i + 1) * 30 * n_frames_per_sec,\n",
    "          (2 * i + 2) * 30 * n_frames_per_sec,\n",
    "          (2 * i + 2) * 30 * n_frames_per_sec -\n",
    "          (2 * i + 1) * 30 * n_frames_per_sec)\n",
    "    # raw_car_cut1 = raw_car._data[:, start_idx:end_idx]\n",
    "    raw_car_cut1 = eeg[:, start_idx:end_idx]\n",
    "    raw_car_cut = np.append(raw_car_cut, raw_car_cut1, axis=1)\n",
    "    mel_data_cut1 = mel_data[(2 * i + 1) * 30 * n_frames_per_sec:(2 * i + 2) *\n",
    "                             30 * n_frames_per_sec]\n",
    "    mel_data_cut = np.append(mel_data_cut, mel_data_cut1, axis=0)\n",
    "# raise\n",
    "mel_data = mel_data_cut\n",
    "\n",
    "print('after cut: ', raw_car_cut.shape, mel_data.shape)\n",
    "# raise\n",
    "#praat\n",
    "\n",
    "#get EEG SR\n",
    "samplingFrequency_EEG = raw_car.info['sfreq']\n",
    "\n",
    "# Calculate the length of the signal\n",
    "length = raw_car_cut.shape[1] / samplingFrequency_EEG\n",
    "print(\"The length of the EEG signal is\", length, \"s\")\n",
    "print(samplingFrequency_EEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8a1d3",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60849991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract HG features\n",
    "print('calculating Hilbert...', raw_car_cut.shape)\n",
    "# eeg_fft = np.empty((n_max_frames, n_freq_bands, n_eeg_channels * (2 * modelOrder_EEG + 1) ))\n",
    "# feat_Hilbert_1 = extractHG(raw_car_cut,samplingFrequency_EEG, windowLength=winL_EEG,frameshift=frameshift_EEG, bandpass_min=1, bandpass_max=200)\n",
    "feat_Hilbert_1 = extractHG(np.rot90(raw_car_cut),\n",
    "                           samplingFrequency_EEG,\n",
    "                           windowLength=winL_EEG,\n",
    "                           frameshift=frameshift_EEG,\n",
    "                           bandpass_min=1,\n",
    "                           bandpass_max=120)\n",
    "# feat_Hilbert_2 = extractHG(np.rot90(current_raw_eeg_data),samplingFrequency_EEG, windowLength=winL_EEG,frameshift=frameshift_EEG, bandpass_min=51, bandpass_max=100)\n",
    "# feat_Hilbert_3 = extractHG(np.rot90(current_raw_eeg_data),samplingFrequency_EEG, windowLength=winL_EEG,frameshift=frameshift_EEG, bandpass_min=101, bandpass_max=150)\n",
    "# feat_Hilbert_4 = extractHG(np.rot90(current_raw_eeg_data),samplingFrequency_EEG, windowLength=winL_EEG,frameshift=frameshift_EEG, bandpass_min=151, bandpass_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack features\n",
    "feat_Hilbert_1 = stackFeatures(feat_Hilbert_1,\n",
    "                               modelOrder=modelOrder_EEG,\n",
    "                               stepSize=stepSize_EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.imshow(np.rot90(feat_Hilbert_1), aspect='auto')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(np.rot90(mel_data).T, aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "eeg = feat_Hilbert_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd726bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = np.min((len(eeg), len(mel_data)))\n",
    "eeg = eeg[0:min_len]\n",
    "mel_data = mel_data[0:min_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mel & iEEG: ', mel_data.shape, feat_Hilbert_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231022c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = np.arange(0, int(0.8 * eeg.shape[0]))\n",
    "test_index = np.arange(int(0.8 * eeg.shape[0]), eeg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation-test split\n",
    "eeg_train = eeg[0:int(len(eeg) * 0.8)]\n",
    "eeg_valid = eeg[int(len(eeg) * 0.8):int(len(eeg) * 0.9)]\n",
    "eeg_test = eeg[int(len(eeg) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95580bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_train = mel_data[0:int(len(mel_data) * 0.8)]\n",
    "melspec_valid = mel_data[int(len(mel_data) * 0.8):int(len(mel_data) * 0.9)]\n",
    "melspec_test = mel_data[int(len(mel_data) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cbe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale input to [0-1]\n",
    "eeg_scaler = MinMaxScaler()\n",
    "# eeg_scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "eeg_train_scaled = eeg_scaler.fit_transform(eeg_train)\n",
    "eeg_valid_scaled = eeg_scaler.transform(eeg_valid)\n",
    "eeg_test_scaled = eeg_scaler.transform(eeg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale outpit mel-spectrogram data to zero mean, unit variances\n",
    "melspec_scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "melspec_train_scaled = melspec_scaler.fit_transform(melspec_train)\n",
    "melspec_valid_scaled = melspec_scaler.transform(melspec_valid)\n",
    "melspec_test_scaled = melspec_scaler.transform(melspec_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c26db",
   "metadata": {},
   "source": [
    "# **2D CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7639158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strided_app(a,\n",
    "                L,\n",
    "                S,\n",
    "                verbose=None):  # Window len = L, Stride len/stepsize = S\n",
    "    shape = a.shape[1:]\n",
    "    nrows = ((a.shape[0] - L) // S) + 1\n",
    "    strides = a.strides\n",
    "    #print(shape, strides)\n",
    "    if verbose:\n",
    "        print(\"strides:\", strides)\n",
    "    return np.lib.stride_tricks.as_strided(a,\n",
    "                                           shape=(nrows, L) + shape,\n",
    "                                           strides=(S * strides[0], ) +\n",
    "                                           strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51476ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = '2D-CNN'\n",
    "result_path = os.path.join(os.getcwd(), f\"results_{method}\")\n",
    "winLength = 0.05\n",
    "frameshift = 0.01\n",
    "audiosr = 16000\n",
    "\n",
    "spectrogram = mel_data\n",
    "data = eeg\n",
    "pt = subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a train and test split from data, test is 20% of the data\n",
    "    train_index = np.arange(0, int(0.8 * data.shape[0]))\n",
    "    test_index = np.arange(int(0.8 * data.shape[0]), data.shape[0])\n",
    "\n",
    "    # Initialize an empty spectrogram to save the reconstruction to\n",
    "    rec_spec = np.zeros(spectrogram.shape)\n",
    "\n",
    "    # Z-Normalize with mean and std from the training data\n",
    "    mu = np.mean(data[train_index, :], axis=0)\n",
    "    std = np.std(data[train_index, :], axis=0)\n",
    "    trainData = (data[train_index, :] - mu) / std\n",
    "    testData = (data[test_index, :] - mu) / std\n",
    "\n",
    "    # Z-Normalize with mean and std from the training data -- output\n",
    "    mu = np.mean(spectrogram[train_index, :], axis=0)\n",
    "    std = np.std(spectrogram[train_index, :], axis=0)\n",
    "    trainSpectrogram = (spectrogram[train_index, :] - mu) / std\n",
    "    testSpectrogram = (spectrogram[test_index, :] - mu) / std\n",
    "\n",
    "    print('Input shape: ', trainData.shape)\n",
    "    print('Input shape: ', testData.shape)\n",
    "        \n",
    "    # Find the right shape for the input, as it should be 3D, like 1143 is 9*127\n",
    "    new_shape = int(trainData.shape[1] / 9)\n",
    "\n",
    "    # reshape input from 1143 to 9*127\n",
    "    trainData = trainData.reshape(-1, 9, new_shape)\n",
    "    testData = testData.reshape(-1, 9, new_shape)\n",
    "    print('Input shape: ', trainData.shape)\n",
    "\n",
    "    sts = 6\n",
    "    window_size = sts * 4 + 1\n",
    "    n_to_skip = np.floor(window_size // 2).astype(np.int64)\n",
    "\n",
    "    print('Input shape: ', trainData.shape)\n",
    "\n",
    "    #conversion to 3D blocks\n",
    "    trainData = strided_app(trainData, window_size, 1)\n",
    "    trainSpectrogram = trainSpectrogram[n_to_skip:(trainSpectrogram.shape[0] - n_to_skip)]\n",
    "\n",
    "    testData = strided_app(testData, window_size, 1)\n",
    "    testSpectrogram = testSpectrogram[n_to_skip:(testSpectrogram.shape[0] - n_to_skip)]\n",
    "\n",
    "    print('Input shape: ', trainData.shape)\n",
    "    print('Input/validation shape: ', testData.shape)\n",
    "    print('Output shape: ', trainSpectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d03b12",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=trainData.shape[1:]))\n",
    "    model.add(Conv2D(filters=10,\n",
    "                     kernel_size=(13, 13),\n",
    "                     strides=(sts, 2),\n",
    "                     activation=tensorflow.nn.swish,\n",
    "                     padding=\"same\",\n",
    "                     kernel_initializer=keras.initializers.he_uniform(seed=None),\n",
    "                     kernel_regularizer=regularizers.l1(0.00001),\n",
    "                     input_shape=trainData.shape[1:]))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters=40, kernel_size=(13, 13), strides=(2, 2), activation=tensorflow.nn.swish,\n",
    "                     padding=\"same\", kernel_initializer=keras.initializers.he_uniform(seed=None),\n",
    "                     kernel_regularizer=regularizers.l1(0.00001)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters=40, kernel_size=(13, 13), strides=(2, 2), activation=tensorflow.nn.swish,\n",
    "                     padding=\"same\", kernel_initializer=keras.initializers.he_uniform(seed=None),\n",
    "                     kernel_regularizer=regularizers.l1(0.00001)))\n",
    "    model.add(Dropout(0.2))\n",
    "   # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  #  model.add(Conv2D(filters=200, kernel_size=(13, 13), strides=(2, 2), activation=tensorflow.nn.swish,\n",
    " #                    padding=\"same\", kernel_initializer=keras.initializers.he_uniform(seed=None),\n",
    " #                    kernel_regularizer=regularizers.l1(0.00001)))\n",
    "  #  model.add(Dropout(0.1))\n",
    "    #model.add(Conv3D(filters=100, kernel_size=(1, 13, 13), strides=(1, 1, 1), activation=tensorflow.nn.swish,\n",
    "                     # padding=\"same\", kernel_initializer=keras.initializers.he_uniform(seed=None),\n",
    "                     # kernel_regularizer=regularizers.l1(0.00001)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(\n",
    "        Dense(100, activation=tensorflow.nn.swish, kernel_initializer=keras.initializers.he_uniform(seed=None),\n",
    "              bias_initializer=keras.initializers.he_uniform(seed=None),\n",
    "              kernel_regularizer=regularizers.l1(0.000005)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(trainSpectrogram.shape[1], activation='linear'))\n",
    "\n",
    "    plot_model(model, to_file=f\"model_{method}.png\", show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    model.compile(\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mean_squared_error'],\n",
    "            optimizer='adam')\n",
    "    earlystopper = EarlyStopping(monitor='val_mean_squared_error', min_delta=0.001, patience=3, verbose=1,\n",
    "                                 mode='auto')\n",
    "    lrr = ReduceLROnPlateau(monitor='val_mean_squared_error', patience=2, verbose=1, factor=0.5, min_lr=0.0001)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    if not (os.path.isdir('models/')):\n",
    "        os.mkdir('models/')\n",
    "\n",
    "    # early stopping to avoid over-training\n",
    "    model_name = 'models/iEEG_to_melspec_2D-CNN_sp-' + pt\n",
    "\n",
    "    # csapot: temporarily disabled\n",
    "    checkp = ModelCheckpoint(\n",
    "        model_name +\n",
    "        '_weights_best.h5',\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='min')\n",
    "\n",
    "    # Run training\n",
    "    history = model.fit(trainData, trainSpectrogram,\n",
    "                        epochs=100, batch_size=32, shuffle=False, verbose=1,\n",
    "                        callbacks=[earlystopper, checkp, lrr],\n",
    "                        validation_data=(testData, testSpectrogram),\n",
    "                        )\n",
    "\n",
    "\n",
    "    # load back best weights\n",
    "    model.load_weights(model_name + '_weights_best.h5')\n",
    "\n",
    "    rec_spec = model.predict(testData)\n",
    "\n",
    "    # inverse transform\n",
    "    # testSpectrogram=(spectrogram[test,:]-mu)/std\n",
    "    rec_spec = rec_spec * std + mu\n",
    "\n",
    "    print('start saving wav')\n",
    "\n",
    "    # Save reconstructed spectrogram\n",
    "    os.makedirs(os.path.join(result_path), exist_ok=True)\n",
    "    np.save(os.path.join(result_path, f'{pt}_predicted_spec.npy'), rec_spec)\n",
    "\n",
    "\n",
    "    # remove model file\n",
    "    os.remove(model_name + '_weights_best.h5')\n",
    "    del model\n",
    "    # Run garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465474b2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "best_val_mse = min(history.history['val_mean_squared_error'])\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(np.rot90(melspec_test_scaled[0:1000]), aspect='auto')\n",
    "axs[0].set_title('EEG Test Scaled')\n",
    "\n",
    "axs[1].imshow(np.rot90(rec_spec[0:1000]), aspect='auto')\n",
    "axs[1].set_title('2D-CNN')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.suptitle('2D-CNN results for patient ' + subject + ' ' + f'Best validation MSE: {best_val_mse:.4f}')\n",
    "plt.savefig(model_name + '_EEG_scaled_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4735d1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Audio synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give SR\n",
    "samplingFrequency = 512\n",
    "# Convert mel spectrogram to audio using Griffin-Lim algorithm\n",
    "audio = librosa.feature.inverse.mel_to_audio(rec_spec, sr=samplingFrequency)\n",
    "\n",
    "# Save the audio to a WAV file\n",
    "output_file = subject+'predicted_audio_2dcnn.wav'\n",
    "sf.write(output_file, audio, samplingFrequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296be6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
